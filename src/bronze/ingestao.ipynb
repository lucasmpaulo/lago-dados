{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16f82a92-9840-438d-9166-4e9bee9c7299",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports biblioteca"
    }
   },
   "outputs": [],
   "source": [
    "import delta\n",
    "\n",
    "def table_exists(database, table):\n",
    "    count = (spark.sql(f\"SHOW TABLES FROM {database}\")\n",
    "                  .filter(f\"database='{database}' AND tableName='{table}'\")\n",
    "                  .count())    \n",
    "    return count == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b1d4814-2010-401b-ad51-285118094bd3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Setup: Parametrização"
    }
   },
   "outputs": [],
   "source": [
    "schema = \"bronze\"\n",
    "tablename = dbutils.widgets.get(\"tablename\")\n",
    "id_field = dbutils.widgets.get(\"id_field\")\n",
    "timestamp_field = dbutils.widgets.get(\"timestamp_field\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5163371-3805-44e8-9245-ce253dd64d47",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingestão Carga Completa"
    }
   },
   "outputs": [],
   "source": [
    "if not table_exists(schema, tablename):\n",
    "    print(\"Tabela não existente, criando.\")\n",
    "    df_full = spark.read.format(\"csv\").options(sep=\";\", header=True).load(f\"/Volumes/workspace/upsell/full_load/{tablename}/\")\n",
    "    (df_full.coalesce(1).write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{schema}.{tablename}\"))\n",
    "else:\n",
    "    print(\"Tabela já existente, ignorando carga completa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7490be8d-4a0a-4591-9bcb-f5b3d772bc3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Atualização da tabela - Incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e4450f4-c012-48e3-a387-84f34a20f859",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ler os arquivos do CDC"
    }
   },
   "outputs": [],
   "source": [
    "# Cria uma view para executar consultas SQL.\n",
    "(spark.read\n",
    "  .format(\"csv\")\n",
    "  .options(sep=\";\", header=True)\n",
    "  .load(f\"/Volumes/workspace/upsell/cdc/{tablename}/\")\n",
    "  .createOrReplaceTempView(F\"view_{tablename}\"))\n",
    "\n",
    "# Consulta para pegar o dado mais recente de cada cliente para realizar o incremental.\n",
    "query = f'''\n",
    "    SELECT * \n",
    "    FROM view_{tablename}\n",
    "    QUALIFY ROW_NUMBER() OVER (PARTITION BY {id_field} ORDER BY {timestamp_field} DESC) = 1\n",
    "'''\n",
    "\n",
    "df_cdc_unique = spark.sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "302f6e67-42aa-427f-8683-03e58c9a6116",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Realizar o Merge da bronze com os dados novos - Escrita do CDC"
    }
   },
   "outputs": [],
   "source": [
    "bronze = delta.DeltaTable.forName(spark, f\"{schema}.{tablename}\")\n",
    "\n",
    "# Consolidação do dado mais recente entre a Bronze e os novos dados que chegou, denominado UPSERT.\n",
    "(bronze.alias(\"b\")\n",
    "       .merge(df_cdc_unique.alias(\"d\"), f\"b.{id_field} = d.{id_field}\")\n",
    "       .whenMatchedDelete(condition = \"d.OP = 'D'\")\n",
    "       .whenMatchedUpdateAll(condition = \"d.OP = 'U'\")\n",
    "       .whenNotMatchedInsertAll(condition = \"d.OP = 'I' or d.OP = 'U'\")\n",
    "       #.execute()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5042236570075985,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "ingestao",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
